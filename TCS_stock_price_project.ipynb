{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sejaltiwari0420-cmd/Business-Analyst-Salary-in-India-2024-Fresher-to-Experienced/blob/main/TCS_stock_price_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stock Prices Predictor-\n",
        "Machine learning proves immensely helpful in many industries in automating tasks that earlier required human labor one such application of ML is predicting whether a particular trade will be profitable or not.\n",
        "\n",
        "we will learn how to predict a signal that indicates whether buying a particular stock will be helpful or not by using ML.\n",
        "\n",
        "which will be explained later in this article.\n",
        "\n",
        "# Importation Libraries-\n",
        "Python libraries make it very easy for us to handle the data and perform typical and complex tasks with a single line of code.\n",
        "\n",
        "Pandas-This library helps to load the data frame in a 2D array format and has multiple functions to perform analysis tasks in one go.\n",
        "\n",
        "Numpy-Numpy arrays are very fast and can perform large computations in a very short time.\n",
        "\n",
        "Matplotlib/Seaborn-This library is used to draw visualizations.\n",
        "\n",
        "XGBoost-This contains the extreme gradient boosting ml algorithm.which helps us to achieve high accuracy on predictions.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gd32i3Vkvhz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Xz93AwGP7Cag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation Dataset-\n",
        "The dataset we will use here to perform the analysis and build a predictive model is TCS Stock Price data. We will use OHLCAV('Open', 'High', 'Low', 'Close','Adj close','Volume') data from 26 December 2024 to 24 December 2025 which is for 1 years for the TCS stocks."
      ],
      "metadata": {
        "id": "TIfSzLje7SKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "\n",
        "stock = \"POWERGRID.NS\"\n",
        "start = dt.datetime(2024, 12, 26)\n",
        "end = dt.datetime(2025, 12, 24)\n",
        "\n",
        "df = yf.download(stock, start, end)"
      ],
      "metadata": {
        "id": "Fwkp0hIkLquh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "cR-BaZRuLyHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "dHrNfh72McIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "uwrPNxPaMhP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "MLm2zHpUMwS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Ey3RZNAjM3ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "NI8_pHBfNFe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.reset_index(drop=True)  # resets index and drops old index\n",
        "df.head()"
      ],
      "metadata": {
        "id": "z0Uwn9UQO7eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "Lhii1MoPPQdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"powergrid.csv\")\n",
        "data01=pd.read_csv(\"powergrid.csv\")\n",
        "data01.head()"
      ],
      "metadata": {
        "id": "dxvBWeR0SV2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({...})  # your data\n",
        "if 'your_key' in df.columns:\n",
        "    value = df['your_key']\n",
        "else:\n",
        "    print(\"Key not found. Check your column names.\")"
      ],
      "metadata": {
        "id": "yfpadXgrWQV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "sNaHuAMMWhAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Candlesticks\n",
        "import plotly.graph_objects as go\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "\n",
        "# Re-download the stock data to get the original df\n",
        "stock = \"POWERGRID.NS\"\n",
        "start = dt.datetime(2024, 12, 26)\n",
        "end = dt.datetime(2025, 12, 24)\n",
        "original_df = yf.download(stock, start, end)\n",
        "\n",
        "# Process the original_df to create data01 correctly\n",
        "# 1. Reset index to make 'Date' a column\n",
        "data01 = original_df.reset_index()\n",
        "\n",
        "# 2. Flatten MultiIndex columns (e.g., ('Close', 'POWERGRID.NS') -> 'Close')\n",
        "new_columns = []\n",
        "for col in data01.columns:\n",
        "    if isinstance(col, tuple):\n",
        "        new_columns.append(col[0]) # Take the first element of the tuple, e.g., 'Open', 'High'\n",
        "    else:\n",
        "        new_columns.append(col) # 'Date' column remains 'Date'\n",
        "data01.columns = new_columns\n",
        "\n",
        "# Ensure 'Date' is datetime type for plotting (important for plotly)\n",
        "data01['Date'] = pd.to_datetime(data01['Date'])\n",
        "\n",
        "fig = go.Figure(data=[go.Candlestick(x=data01['Date'],\n",
        "                                     open=data01['Open'],\n",
        "                                     high=data01['High'],\n",
        "                                     low=data01['Low'],\n",
        "                                     close=data01['Close'])])\n",
        "fig.show()\n",
        "#fig.update_layout(xaxis_rangeslider_visible=False)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "VvHKhDVXPiWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Date', 'Adj Close'], axis=1, errors='ignore')\n",
        "if 'Date' in df.columns and 'Adj Close' in df.columns:\n",
        "    df = df.drop(['Date', 'Adj Close'], axis=1)\n",
        "else:\n",
        "    print(\"One or both columns do not exist in the DataFrame.\")"
      ],
      "metadata": {
        "id": "EcEIeve8Wzzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "zgFT7xXlXRE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "j5MnPRJXbBqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(data01['Close'])\n",
        "plt.xlabel('Date', fontsize=18)\n",
        "plt.ylabel('Close Price USD ($)', fontsize=18)"
      ],
      "metadata": {
        "id": "aEGI4hPYbEtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.title('Open Price History')\n",
        "plt.plot(data01['Open'])\n",
        "plt.xlabel('Date', fontsize=18)\n",
        "plt.ylabel('Open Price USD ($)', fontsize=18)"
      ],
      "metadata": {
        "id": "ZaYt-92Rei19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.title('High Price History')\n",
        "plt.plot(data01['High'])\n",
        "plt.xlabel('Date', fontsize=18)\n",
        "plt.ylabel('High Price USD ($)', fontsize=18)"
      ],
      "metadata": {
        "id": "1bysh_nIe9II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.title('Low Price History')\n",
        "plt.plot(data01['Low'])\n",
        "plt.xlabel('Date', fontsize=18)\n",
        "plt.ylabel('Low Price USD ($)', fontsize=18)"
      ],
      "metadata": {
        "id": "BhvK6D2wfFOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.title('Close Price History')\n",
        "plt.plot(data01['Close'])\n",
        "plt.xlabel('Date', fontsize=18)\n",
        "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SfP3APNQbazr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(data01['Close'], label=f'{stock}')"
      ],
      "metadata": {
        "id": "RLPqFy2sb5ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Moving Average\n",
        "#[10,20,30,40,50,60,70,80,90,100]\n",
        "#Moving Average for last 5days->null null null null\n",
        "\n",
        "temp_data=[10,20,30,40,50,60,70,80,90,100]\n",
        "print(sum(temp_data[0:5])/5)"
      ],
      "metadata": {
        "id": "Ly5GgraWfggj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1TBsoX7wfIar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df01 = pd.DataFrame(temp_data)\n",
        "df01"
      ],
      "metadata": {
        "id": "HF88_myjg_NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering-\n",
        "Feature Engineering helps to derive some valuable features from the existing ones. These extra features sometimes help in increasing the performance of the model significantly and certainly help to gain deeper insights into the data."
      ],
      "metadata": {
        "id": "Hbxg-xFAilhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# The 'df' DataFrame was overwritten. We should use 'data01' for the stock data.\n",
        "# data01 has an extra header row at index 0 from the CSV read; the actual data starts from index 1.\n",
        "# We'll create a temporary DataFrame from the valid rows of data01.\n",
        "\n",
        "temp_df = data01.iloc[1:].copy()\n",
        "\n",
        "# Ensure the 'Date' column is converted to datetime objects to extract the month\n",
        "temp_df['Date'] = pd.to_datetime(temp_df['Date'])\n",
        "\n",
        "# Extract month from the 'Date' column\n",
        "temp_df['month'] = temp_df['Date'].dt.month\n",
        "\n",
        "# Create the 'is_quarter_end' feature using numpy.where\n",
        "temp_df['is_quarter_end'] = np.where(temp_df['month'] % 3 == 0, 1, 0)\n",
        "\n",
        "# Assign the processed DataFrame back to df for consistency with subsequent steps\n",
        "df = temp_df\n",
        "df.head()"
      ],
      "metadata": {
        "id": "AIzfoEIgivhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['year'] = df['Date'].dt.year # Extract year from 'Date' column\n",
        "\n",
        "# List of columns that should be numeric and are relevant for mean calculation\n",
        "price_and_volume_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "\n",
        "# Explicitly convert these columns to numeric, coercing errors to NaN\n",
        "for col in price_and_volume_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Now, group by 'year' and calculate the mean *only* for the numeric columns that are intended for it.\n",
        "data_grouped = df.groupby('year')[price_and_volume_cols].mean()\n",
        "\n",
        "plt.subplots(figsize=(20,10))\n",
        "\n",
        "for i, col in enumerate(['Open', 'High', 'Low', 'Close']):\n",
        "  plt.subplot(2,2,i+1)\n",
        "  data_grouped[col].plot.bar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0s6HW0kZjGqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify all numeric columns that make sense to average\n",
        "numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'month', 'year']\n",
        "\n",
        "# Select only the relevant numeric columns from the DataFrame\n",
        "# before grouping by 'is_quarter_end' and calculating the mean.\n",
        "df[numeric_columns].groupby(df['is_quarter_end']).mean()"
      ],
      "metadata": {
        "id": "tzVkc3Kkjw2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ma100 = df['Close'].rolling(100).mean()\n",
        "ma100"
      ],
      "metadata": {
        "id": "EbnQgYiTnLoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(df['High'], label=f'{stock}High Price',linewidth=1)\n",
        "plt.title(f'{stock}high prices over time')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tXPj-uGjnUTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Close'].ewm(span=100,adjust=False).mean()\n"
      ],
      "metadata": {
        "id": "SuTtSht7ohCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ema100 = df['Close'].ewm(span=100,adjust=False).mean()\n",
        "ema200=df['Close'].ewm(span=200,adjust=False).mean()\n",
        "\n",
        "# Drop non-numeric columns that cause issues with pct_change()\n",
        "numeric_df = df.drop(columns=['Price', 'level_0', 'index', 'Date'], errors='ignore')\n",
        "numeric_df.pct_change()"
      ],
      "metadata": {
        "id": "tuJxA_7qpOkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training & Testing\n",
        "data_training = pd.DataFrame(df['Close'][0:int(len(df)*0.70)])\n",
        "data_testing = pd.DataFrame(df['Close'][int(len(df)*0.70): int(len(df))])\n",
        "data_training.shape"
      ],
      "metadata": {
        "id": "UoJib4FMpGZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_testing.shape"
      ],
      "metadata": {
        "id": "vqcDQXy3qUXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "data_training_array = scaler.fit_transform(data_training)\n",
        "data_training_array"
      ],
      "metadata": {
        "id": "5thk_2e_qc-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "for i in range(100,data_training_array.shape[0]):\n",
        "  x_train.append(data_training_array[i-100: i])\n",
        "  y_train.append(data_training_array[i,0])\n",
        "x_train,y_train = np.array(x_train),np.array(y_train)\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "W3Jj5HgCq_bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Development and Evaluation\n",
        "Now is the time to train some state-of-the-art machine learning models(Logistic Regression, Support Vector Machine, XGBClassifier), and then based on their performance on the training and validation data we will choose which ML model is serving the purpose at hand better."
      ],
      "metadata": {
        "id": "CYVnnZ88yxxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Building\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.models import Sequential\n",
        "model = Sequential()\n",
        "# LSTM Input ->3D Array(batch_size,time_steps,seq_len)LSTM 2D OR 3D 2D(batch_sizem units)3D(batch_size,time_steps,units)"
      ],
      "metadata": {
        "id": "7EfTmHQmrmQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(x_train.shape[1],1))) # Explicit Input layer\n",
        "model.add(LSTM(units=50,activation='relu',return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=60,activation='relu',return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(units=80,activation='relu',return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(units=120,activation='relu', return_sequences=False)) # Explicitly set return_sequences=False\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "nUqAvwoetOIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "zvHvrAYMtzTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "\n",
        "# Ensure y_train has the correct shape for a single output\n",
        "# y_train is currently (74,), reshape to (74, 1)\n",
        "if y_train.ndim == 1:\n",
        "    y_train_reshaped = y_train.reshape(-1, 1)\n",
        "else:\n",
        "    y_train_reshaped = y_train\n",
        "\n",
        "model.fit(x_train, y_train_reshaped, epochs=50)"
      ],
      "metadata": {
        "id": "s5GNqDzvt8N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "past_100_days = data_training.tail(100)\n",
        "final_df = pd.concat([past_100_days, data_testing], ignore_index=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "g7QHI62Euoca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = scaler.fit_transform(final_df)"
      ],
      "metadata": {
        "id": "l89JiDcBv30T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=[]\n",
        "y_test=[]\n",
        "for i in range(100,input_data.shape[0]):\n",
        "  x_test.append(input_data[i-100: i])\n",
        "  y_test.append(input_data[i,0])\n",
        "  x_train,y_train = np.array(x_train),np.array(y_train)\n",
        "x_test,y_test = np.array(x_test),np.array(y_test)\n",
        "x_test.shape"
      ],
      "metadata": {
        "id": "mQTkhLn8vCyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted=model.predict(x_test)"
      ],
      "metadata": {
        "id": "AWM_3GjYwVDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted.shape"
      ],
      "metadata": {
        "id": "zTQwE6oLwsfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.scale_"
      ],
      "metadata": {
        "id": "nY9237iVwxkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_factor=1/0.0035166\n",
        "y_predicted=y_predicted*scaler_factor\n",
        "y_test=y_test*scaler_factor"
      ],
      "metadata": {
        "id": "n4eE14Qgw7ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_test,'b',label='Original Price')\n",
        "plt.plot(y_predicted,'r',label='Predicted Price')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BtllaOTnxIpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('keras_model.h5')\n",
        "model.save('stock_dl_model.h5')"
      ],
      "metadata": {
        "id": "8JlKX-OFxaPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion:\n",
        "We can observe that the accuracy achieved by the state-of-the-art ML model is no better than simply guessing with a probability of 50%. Possible reasons for this may be the lack of data or using a very simple model to perform such a complex task as Stock Market prediction."
      ],
      "metadata": {
        "id": "u5_REe_7yDNQ"
      }
    }
  ]
}